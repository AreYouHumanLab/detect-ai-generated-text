2023-12-16 16:35:45,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-16 16:35:45,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-16 16:35:45,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-16 16:35:45,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-16 16:36:10,921:INFO:PyCaret ClassificationExperiment
2023-12-16 16:36:10,921:INFO:Logging name: clf-default-name
2023-12-16 16:36:10,921:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-12-16 16:36:10,921:INFO:version 3.2.0
2023-12-16 16:36:10,922:INFO:Initializing setup()
2023-12-16 16:36:10,922:INFO:self.USI: beea
2023-12-16 16:36:10,922:INFO:self._variable_keys: {'exp_name_log', 'X_train', 'y', 'logging_param', 'fix_imbalance', '_ml_usecase', 'X', 'log_plots_param', 'USI', 'fold_groups_param', 'data', 'y_test', 'fold_shuffle_param', 'X_test', 'idx', 'pipeline', 'target_param', 'y_train', 'memory', 'seed', 'html_param', '_available_plots', 'gpu_n_jobs_param', 'is_multiclass', 'n_jobs_param', 'exp_id', 'gpu_param', 'fold_generator'}
2023-12-16 16:36:10,922:INFO:Checking environment
2023-12-16 16:36:10,922:INFO:python_version: 3.11.5
2023-12-16 16:36:10,922:INFO:python_build: ('main', 'Sep 11 2023 08:31:25')
2023-12-16 16:36:10,922:INFO:machine: arm64
2023-12-16 16:36:10,922:INFO:platform: macOS-13.2.1-arm64-arm-64bit
2023-12-16 16:36:10,922:INFO:Memory: svmem(total=17179869184, available=5817057280, percent=66.1, used=7425835008, free=486211584, active=5346525184, inactive=5317722112, wired=2079309824)
2023-12-16 16:36:10,922:INFO:Physical Core: 8
2023-12-16 16:36:10,922:INFO:Logical Core: 8
2023-12-16 16:36:10,922:INFO:Checking libraries
2023-12-16 16:36:10,922:INFO:System:
2023-12-16 16:36:10,922:INFO:    python: 3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]
2023-12-16 16:36:10,922:INFO:executable: /Users/heeseung/miniconda3/envs/kaggle/bin/python
2023-12-16 16:36:10,922:INFO:   machine: macOS-13.2.1-arm64-arm-64bit
2023-12-16 16:36:10,922:INFO:PyCaret required dependencies:
2023-12-16 16:36:11,614:INFO:                 pip: 23.3.1
2023-12-16 16:36:11,614:INFO:          setuptools: 68.2.2
2023-12-16 16:36:11,614:INFO:             pycaret: 3.2.0
2023-12-16 16:36:11,615:INFO:             IPython: 8.18.1
2023-12-16 16:36:11,615:INFO:          ipywidgets: 8.1.1
2023-12-16 16:36:11,615:INFO:                tqdm: 4.66.1
2023-12-16 16:36:11,615:INFO:               numpy: 1.25.2
2023-12-16 16:36:11,615:INFO:              pandas: 1.5.3
2023-12-16 16:36:11,615:INFO:              jinja2: 3.1.2
2023-12-16 16:36:11,615:INFO:               scipy: 1.10.1
2023-12-16 16:36:11,615:INFO:              joblib: 1.3.2
2023-12-16 16:36:11,615:INFO:             sklearn: 1.2.2
2023-12-16 16:36:11,615:INFO:                pyod: 1.1.2
2023-12-16 16:36:11,615:INFO:            imblearn: 0.11.0
2023-12-16 16:36:11,615:INFO:   category_encoders: 2.6.3
2023-12-16 16:36:11,615:INFO:            lightgbm: 4.1.0
2023-12-16 16:36:11,615:INFO:               numba: 0.58.1
2023-12-16 16:36:11,615:INFO:            requests: 2.31.0
2023-12-16 16:36:11,615:INFO:          matplotlib: 3.6.0
2023-12-16 16:36:11,615:INFO:          scikitplot: 0.3.7
2023-12-16 16:36:11,615:INFO:         yellowbrick: 1.5
2023-12-16 16:36:11,615:INFO:              plotly: 5.18.0
2023-12-16 16:36:11,615:INFO:    plotly-resampler: Not installed
2023-12-16 16:36:11,615:INFO:             kaleido: 0.2.1
2023-12-16 16:36:11,615:INFO:           schemdraw: 0.15
2023-12-16 16:36:11,615:INFO:         statsmodels: 0.14.1
2023-12-16 16:36:11,615:INFO:              sktime: 0.21.1
2023-12-16 16:36:11,615:INFO:               tbats: 1.1.3
2023-12-16 16:36:11,615:INFO:            pmdarima: 2.0.4
2023-12-16 16:36:11,615:INFO:              psutil: 5.9.0
2023-12-16 16:36:11,615:INFO:          markupsafe: 2.1.3
2023-12-16 16:36:11,615:INFO:             pickle5: Not installed
2023-12-16 16:36:11,615:INFO:         cloudpickle: 3.0.0
2023-12-16 16:36:11,615:INFO:         deprecation: 2.1.0
2023-12-16 16:36:11,615:INFO:              xxhash: 3.4.1
2023-12-16 16:36:11,615:INFO:           wurlitzer: 3.0.3
2023-12-16 16:36:11,615:INFO:PyCaret optional dependencies:
2023-12-16 16:36:11,627:INFO:                shap: Not installed
2023-12-16 16:36:11,627:INFO:           interpret: Not installed
2023-12-16 16:36:11,627:INFO:                umap: Not installed
2023-12-16 16:36:11,627:INFO:     ydata_profiling: 4.6.3
2023-12-16 16:36:11,627:INFO:  explainerdashboard: Not installed
2023-12-16 16:36:11,627:INFO:             autoviz: Not installed
2023-12-16 16:36:11,627:INFO:           fairlearn: Not installed
2023-12-16 16:36:11,627:INFO:          deepchecks: Not installed
2023-12-16 16:36:11,627:INFO:             xgboost: Not installed
2023-12-16 16:36:11,627:INFO:            catboost: Not installed
2023-12-16 16:36:11,627:INFO:              kmodes: Not installed
2023-12-16 16:36:11,627:INFO:             mlxtend: Not installed
2023-12-16 16:36:11,627:INFO:       statsforecast: Not installed
2023-12-16 16:36:11,627:INFO:        tune_sklearn: Not installed
2023-12-16 16:36:11,627:INFO:                 ray: Not installed
2023-12-16 16:36:11,627:INFO:            hyperopt: Not installed
2023-12-16 16:36:11,627:INFO:              optuna: Not installed
2023-12-16 16:36:11,627:INFO:               skopt: Not installed
2023-12-16 16:36:11,627:INFO:              mlflow: Not installed
2023-12-16 16:36:11,627:INFO:              gradio: Not installed
2023-12-16 16:36:11,627:INFO:             fastapi: Not installed
2023-12-16 16:36:11,627:INFO:             uvicorn: Not installed
2023-12-16 16:36:11,627:INFO:              m2cgen: Not installed
2023-12-16 16:36:11,627:INFO:           evidently: Not installed
2023-12-16 16:36:11,627:INFO:               fugue: Not installed
2023-12-16 16:36:11,627:INFO:           streamlit: Not installed
2023-12-16 16:36:11,627:INFO:             prophet: Not installed
2023-12-16 16:36:11,627:INFO:None
2023-12-16 16:36:11,627:INFO:Set up data.
2023-12-16 16:36:11,652:INFO:Set up folding strategy.
2023-12-16 16:36:11,652:INFO:Set up train/test split.
2023-12-16 16:36:11,660:INFO:Set up index.
2023-12-16 16:36:11,660:INFO:Assigning column types.
2023-12-16 16:36:11,661:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-12-16 16:36:11,681:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-12-16 16:36:11,682:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-16 16:36:11,695:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:36:11,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:36:11,712:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-12-16 16:36:11,713:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-16 16:36:11,723:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:36:11,723:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:36:11,723:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-12-16 16:36:11,741:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-16 16:36:11,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:36:11,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:36:11,769:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-16 16:36:11,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:36:11,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:36:11,780:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-12-16 16:36:11,807:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:36:11,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:36:11,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:36:11,836:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:36:11,837:INFO:Preparing preprocessing pipeline...
2023-12-16 16:36:11,838:INFO:Set up simple imputation.
2023-12-16 16:36:11,838:INFO:Set up encoding of categorical features.
2023-12-16 16:36:11,838:INFO:Set up imbalanced handling.
2023-12-16 16:36:11,964:INFO:Finished creating preprocessing pipeline.
2023-12-16 16:36:11,968:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/g6/2h3s7_hj4dn773vqdb1z9c6w0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['prompt_id'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_impu...
                                    transformer=TargetEncoder(cols=['id',
                                                                    'text'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2023-12-16 16:36:11,968:INFO:Creating final display dataframe.
2023-12-16 16:37:13,204:INFO:PyCaret ClassificationExperiment
2023-12-16 16:37:13,204:INFO:Logging name: clf-default-name
2023-12-16 16:37:13,204:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-12-16 16:37:13,204:INFO:version 3.2.0
2023-12-16 16:37:13,204:INFO:Initializing setup()
2023-12-16 16:37:13,204:INFO:self.USI: 4507
2023-12-16 16:37:13,204:INFO:self._variable_keys: {'exp_name_log', 'X_train', 'y', 'logging_param', 'fix_imbalance', '_ml_usecase', 'X', 'log_plots_param', 'USI', 'fold_groups_param', 'data', 'y_test', 'fold_shuffle_param', 'X_test', 'idx', 'pipeline', 'target_param', 'y_train', 'memory', 'seed', 'html_param', '_available_plots', 'gpu_n_jobs_param', 'is_multiclass', 'n_jobs_param', 'exp_id', 'gpu_param', 'fold_generator'}
2023-12-16 16:37:13,204:INFO:Checking environment
2023-12-16 16:37:13,204:INFO:python_version: 3.11.5
2023-12-16 16:37:13,204:INFO:python_build: ('main', 'Sep 11 2023 08:31:25')
2023-12-16 16:37:13,204:INFO:machine: arm64
2023-12-16 16:37:13,204:INFO:platform: macOS-13.2.1-arm64-arm-64bit
2023-12-16 16:37:13,204:INFO:Memory: svmem(total=17179869184, available=5882085376, percent=65.8, used=7365459968, free=537411584, active=5362499584, inactive=5321179136, wired=2002960384)
2023-12-16 16:37:13,204:INFO:Physical Core: 8
2023-12-16 16:37:13,204:INFO:Logical Core: 8
2023-12-16 16:37:13,204:INFO:Checking libraries
2023-12-16 16:37:13,204:INFO:System:
2023-12-16 16:37:13,204:INFO:    python: 3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]
2023-12-16 16:37:13,204:INFO:executable: /Users/heeseung/miniconda3/envs/kaggle/bin/python
2023-12-16 16:37:13,204:INFO:   machine: macOS-13.2.1-arm64-arm-64bit
2023-12-16 16:37:13,204:INFO:PyCaret required dependencies:
2023-12-16 16:37:13,204:INFO:                 pip: 23.3.1
2023-12-16 16:37:13,204:INFO:          setuptools: 68.2.2
2023-12-16 16:37:13,204:INFO:             pycaret: 3.2.0
2023-12-16 16:37:13,204:INFO:             IPython: 8.18.1
2023-12-16 16:37:13,204:INFO:          ipywidgets: 8.1.1
2023-12-16 16:37:13,204:INFO:                tqdm: 4.66.1
2023-12-16 16:37:13,204:INFO:               numpy: 1.25.2
2023-12-16 16:37:13,204:INFO:              pandas: 1.5.3
2023-12-16 16:37:13,204:INFO:              jinja2: 3.1.2
2023-12-16 16:37:13,204:INFO:               scipy: 1.10.1
2023-12-16 16:37:13,204:INFO:              joblib: 1.3.2
2023-12-16 16:37:13,204:INFO:             sklearn: 1.2.2
2023-12-16 16:37:13,204:INFO:                pyod: 1.1.2
2023-12-16 16:37:13,204:INFO:            imblearn: 0.11.0
2023-12-16 16:37:13,204:INFO:   category_encoders: 2.6.3
2023-12-16 16:37:13,204:INFO:            lightgbm: 4.1.0
2023-12-16 16:37:13,204:INFO:               numba: 0.58.1
2023-12-16 16:37:13,204:INFO:            requests: 2.31.0
2023-12-16 16:37:13,204:INFO:          matplotlib: 3.6.0
2023-12-16 16:37:13,204:INFO:          scikitplot: 0.3.7
2023-12-16 16:37:13,204:INFO:         yellowbrick: 1.5
2023-12-16 16:37:13,204:INFO:              plotly: 5.18.0
2023-12-16 16:37:13,204:INFO:    plotly-resampler: Not installed
2023-12-16 16:37:13,205:INFO:             kaleido: 0.2.1
2023-12-16 16:37:13,205:INFO:           schemdraw: 0.15
2023-12-16 16:37:13,205:INFO:         statsmodels: 0.14.1
2023-12-16 16:37:13,205:INFO:              sktime: 0.21.1
2023-12-16 16:37:13,205:INFO:               tbats: 1.1.3
2023-12-16 16:37:13,205:INFO:            pmdarima: 2.0.4
2023-12-16 16:37:13,205:INFO:              psutil: 5.9.0
2023-12-16 16:37:13,205:INFO:          markupsafe: 2.1.3
2023-12-16 16:37:13,205:INFO:             pickle5: Not installed
2023-12-16 16:37:13,205:INFO:         cloudpickle: 3.0.0
2023-12-16 16:37:13,205:INFO:         deprecation: 2.1.0
2023-12-16 16:37:13,205:INFO:              xxhash: 3.4.1
2023-12-16 16:37:13,205:INFO:           wurlitzer: 3.0.3
2023-12-16 16:37:13,205:INFO:PyCaret optional dependencies:
2023-12-16 16:37:13,205:INFO:                shap: Not installed
2023-12-16 16:37:13,205:INFO:           interpret: Not installed
2023-12-16 16:37:13,205:INFO:                umap: Not installed
2023-12-16 16:37:13,205:INFO:     ydata_profiling: 4.6.3
2023-12-16 16:37:13,205:INFO:  explainerdashboard: Not installed
2023-12-16 16:37:13,205:INFO:             autoviz: Not installed
2023-12-16 16:37:13,205:INFO:           fairlearn: Not installed
2023-12-16 16:37:13,205:INFO:          deepchecks: Not installed
2023-12-16 16:37:13,205:INFO:             xgboost: Not installed
2023-12-16 16:37:13,205:INFO:            catboost: Not installed
2023-12-16 16:37:13,205:INFO:              kmodes: Not installed
2023-12-16 16:37:13,205:INFO:             mlxtend: Not installed
2023-12-16 16:37:13,205:INFO:       statsforecast: Not installed
2023-12-16 16:37:13,205:INFO:        tune_sklearn: Not installed
2023-12-16 16:37:13,205:INFO:                 ray: Not installed
2023-12-16 16:37:13,205:INFO:            hyperopt: Not installed
2023-12-16 16:37:13,205:INFO:              optuna: Not installed
2023-12-16 16:37:13,205:INFO:               skopt: Not installed
2023-12-16 16:37:13,205:INFO:              mlflow: Not installed
2023-12-16 16:37:13,205:INFO:              gradio: Not installed
2023-12-16 16:37:13,205:INFO:             fastapi: Not installed
2023-12-16 16:37:13,205:INFO:             uvicorn: Not installed
2023-12-16 16:37:13,205:INFO:              m2cgen: Not installed
2023-12-16 16:37:13,205:INFO:           evidently: Not installed
2023-12-16 16:37:13,205:INFO:               fugue: Not installed
2023-12-16 16:37:13,205:INFO:           streamlit: Not installed
2023-12-16 16:37:13,205:INFO:             prophet: Not installed
2023-12-16 16:37:13,205:INFO:None
2023-12-16 16:37:13,205:INFO:Set up data.
2023-12-16 16:37:13,223:INFO:Set up folding strategy.
2023-12-16 16:37:13,223:INFO:Set up train/test split.
2023-12-16 16:37:13,228:INFO:Set up index.
2023-12-16 16:37:13,229:INFO:Assigning column types.
2023-12-16 16:37:13,230:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-12-16 16:37:13,248:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-12-16 16:37:13,248:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-16 16:37:13,259:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:37:13,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:37:13,277:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-12-16 16:37:13,277:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-16 16:37:13,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:37:13,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:37:13,288:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-12-16 16:37:13,306:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-16 16:37:13,317:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:37:13,317:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:37:13,335:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-12-16 16:37:13,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:37:13,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:37:13,346:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-12-16 16:37:13,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:37:13,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:37:13,408:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:37:13,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:37:13,409:INFO:Preparing preprocessing pipeline...
2023-12-16 16:37:13,410:INFO:Set up simple imputation.
2023-12-16 16:37:13,410:INFO:Set up encoding of categorical features.
2023-12-16 16:37:13,520:INFO:Finished creating preprocessing pipeline.
2023-12-16 16:37:13,522:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/g6/2h3s7_hj4dn773vqdb1z9c6w0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['prompt_id'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_impu...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['id', 'text'],
                                    transformer=TargetEncoder(cols=['id',
                                                                    'text'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2023-12-16 16:37:13,522:INFO:Creating final display dataframe.
2023-12-16 16:37:13,814:INFO:Setup _display_container:                     Description             Value
0                    Session id              7936
1                        Target         generated
2                   Target type            Binary
3           Original data shape         (1378, 4)
4        Transformed data shape         (1378, 4)
5   Transformed train set shape          (964, 4)
6    Transformed test set shape          (414, 4)
7              Numeric features                 1
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              4507
2023-12-16 16:37:13,845:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:37:13,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:37:13,874:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:37:13,874:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-12-16 16:37:13,875:INFO:setup() successfully completed in 0.67s...............
2023-12-16 16:38:01,713:INFO:Initializing compare_models()
2023-12-16 16:38:01,714:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2023-12-16 16:38:01,714:INFO:Checking exceptions
2023-12-16 16:38:01,718:INFO:Preparing display monitor
2023-12-16 16:38:01,758:INFO:Initializing Logistic Regression
2023-12-16 16:38:01,758:INFO:Total runtime is 9.250640869140624e-06 minutes
2023-12-16 16:38:01,761:INFO:SubProcess create_model() called ==================================
2023-12-16 16:38:01,762:INFO:Initializing create_model()
2023-12-16 16:38:01,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x285da8190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-16 16:38:01,762:INFO:Checking exceptions
2023-12-16 16:38:01,762:INFO:Importing libraries
2023-12-16 16:38:01,762:INFO:Copying training dataset
2023-12-16 16:38:01,766:INFO:Defining folds
2023-12-16 16:38:01,767:INFO:Declaring metric variables
2023-12-16 16:38:01,771:INFO:Importing untrained model
2023-12-16 16:38:01,778:INFO:Logistic Regression Imported successfully
2023-12-16 16:38:01,784:INFO:Starting cross validation
2023-12-16 16:38:01,786:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-16 16:38:01,803:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2023-12-16 16:38:03,456:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:03,458:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,460:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,464:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:03,465:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:03,587:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:03,588:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:03,588:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,589:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,589:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:03,590:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:03,591:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,593:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,598:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:03,601:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:03,624:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:03,625:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,625:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,626:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:03,626:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:03,633:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:03,635:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,636:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,637:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:03,637:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:03,649:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:03,651:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,652:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,653:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:03,653:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:03,657:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:03,658:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,659:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,660:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:03,660:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:03,661:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,682:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,725:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:03,725:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,726:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,726:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:03,726:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:03,735:INFO:Calculating mean and std
2023-12-16 16:38:03,736:INFO:Creating metrics dataframe
2023-12-16 16:38:03,738:INFO:Uploading results into container
2023-12-16 16:38:03,738:INFO:Uploading model into container now
2023-12-16 16:38:03,738:INFO:_master_model_container: 1
2023-12-16 16:38:03,738:INFO:_display_container: 2
2023-12-16 16:38:03,739:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7936, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-12-16 16:38:03,739:INFO:create_model() successfully completed......................................
2023-12-16 16:38:03,803:INFO:SubProcess create_model() end ==================================
2023-12-16 16:38:03,803:INFO:Creating metrics dataframe
2023-12-16 16:38:03,806:INFO:Initializing K Neighbors Classifier
2023-12-16 16:38:03,806:INFO:Total runtime is 0.03413960138956706 minutes
2023-12-16 16:38:03,807:INFO:SubProcess create_model() called ==================================
2023-12-16 16:38:03,808:INFO:Initializing create_model()
2023-12-16 16:38:03,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x285da8190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-16 16:38:03,808:INFO:Checking exceptions
2023-12-16 16:38:03,808:INFO:Importing libraries
2023-12-16 16:38:03,808:INFO:Copying training dataset
2023-12-16 16:38:03,810:INFO:Defining folds
2023-12-16 16:38:03,810:INFO:Declaring metric variables
2023-12-16 16:38:03,812:INFO:Importing untrained model
2023-12-16 16:38:03,813:INFO:K Neighbors Classifier Imported successfully
2023-12-16 16:38:03,815:INFO:Starting cross validation
2023-12-16 16:38:03,816:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-16 16:38:03,818:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2023-12-16 16:38:03,914:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:03,916:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,916:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,917:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:03,917:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:03,919:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:03,920:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,920:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,921:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:03,921:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:03,935:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,940:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,948:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:03,950:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,950:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,951:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:03,951:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:03,959:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:03,959:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,960:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,961:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:03,961:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:03,964:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:03,965:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,966:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,966:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:03,967:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:03,983:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:03,984:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,985:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:03,985:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:03,985:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:03,999:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:03,999:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,000:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,000:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,001:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,007:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,008:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,008:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,009:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,009:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,014:INFO:Calculating mean and std
2023-12-16 16:38:04,015:INFO:Creating metrics dataframe
2023-12-16 16:38:04,016:INFO:Uploading results into container
2023-12-16 16:38:04,016:INFO:Uploading model into container now
2023-12-16 16:38:04,017:INFO:_master_model_container: 2
2023-12-16 16:38:04,017:INFO:_display_container: 2
2023-12-16 16:38:04,017:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-12-16 16:38:04,017:INFO:create_model() successfully completed......................................
2023-12-16 16:38:04,073:INFO:SubProcess create_model() end ==================================
2023-12-16 16:38:04,073:INFO:Creating metrics dataframe
2023-12-16 16:38:04,078:INFO:Initializing Naive Bayes
2023-12-16 16:38:04,078:INFO:Total runtime is 0.03866887092590332 minutes
2023-12-16 16:38:04,079:INFO:SubProcess create_model() called ==================================
2023-12-16 16:38:04,079:INFO:Initializing create_model()
2023-12-16 16:38:04,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x285da8190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-16 16:38:04,079:INFO:Checking exceptions
2023-12-16 16:38:04,079:INFO:Importing libraries
2023-12-16 16:38:04,079:INFO:Copying training dataset
2023-12-16 16:38:04,081:INFO:Defining folds
2023-12-16 16:38:04,081:INFO:Declaring metric variables
2023-12-16 16:38:04,082:INFO:Importing untrained model
2023-12-16 16:38:04,083:INFO:Naive Bayes Imported successfully
2023-12-16 16:38:04,085:INFO:Starting cross validation
2023-12-16 16:38:04,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-16 16:38:04,087:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2023-12-16 16:38:04,176:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,179:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,179:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,180:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,181:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,181:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,184:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,185:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,188:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,188:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,189:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,189:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,189:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,189:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,189:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,189:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,189:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,192:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,193:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,194:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,194:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,195:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,224:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,224:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,225:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,225:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,225:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,234:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,234:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,235:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,235:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,236:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,236:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,236:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,237:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,237:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,237:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,243:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,243:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,244:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,244:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,245:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,251:INFO:Calculating mean and std
2023-12-16 16:38:04,251:INFO:Creating metrics dataframe
2023-12-16 16:38:04,252:INFO:Uploading results into container
2023-12-16 16:38:04,252:INFO:Uploading model into container now
2023-12-16 16:38:04,253:INFO:_master_model_container: 3
2023-12-16 16:38:04,253:INFO:_display_container: 2
2023-12-16 16:38:04,253:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-12-16 16:38:04,253:INFO:create_model() successfully completed......................................
2023-12-16 16:38:04,306:INFO:SubProcess create_model() end ==================================
2023-12-16 16:38:04,306:INFO:Creating metrics dataframe
2023-12-16 16:38:04,310:INFO:Initializing Decision Tree Classifier
2023-12-16 16:38:04,310:INFO:Total runtime is 0.042536453406016035 minutes
2023-12-16 16:38:04,311:INFO:SubProcess create_model() called ==================================
2023-12-16 16:38:04,312:INFO:Initializing create_model()
2023-12-16 16:38:04,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x285da8190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-16 16:38:04,312:INFO:Checking exceptions
2023-12-16 16:38:04,312:INFO:Importing libraries
2023-12-16 16:38:04,312:INFO:Copying training dataset
2023-12-16 16:38:04,314:INFO:Defining folds
2023-12-16 16:38:04,314:INFO:Declaring metric variables
2023-12-16 16:38:04,315:INFO:Importing untrained model
2023-12-16 16:38:04,316:INFO:Decision Tree Classifier Imported successfully
2023-12-16 16:38:04,318:INFO:Starting cross validation
2023-12-16 16:38:04,319:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-16 16:38:04,320:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2023-12-16 16:38:04,397:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,397:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,398:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,398:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,399:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,400:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,400:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,400:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,401:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,402:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,402:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,409:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,415:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,416:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,416:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,417:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,417:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,426:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,427:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,427:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,428:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,428:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,436:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,437:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,437:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,438:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,438:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,455:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,455:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,456:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,456:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,456:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,460:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,460:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,461:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,461:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,462:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,470:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:04,470:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,471:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,471:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,472:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,482:INFO:Calculating mean and std
2023-12-16 16:38:04,482:INFO:Creating metrics dataframe
2023-12-16 16:38:04,484:INFO:Uploading results into container
2023-12-16 16:38:04,484:INFO:Uploading model into container now
2023-12-16 16:38:04,484:INFO:_master_model_container: 4
2023-12-16 16:38:04,484:INFO:_display_container: 2
2023-12-16 16:38:04,484:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7936, splitter='best')
2023-12-16 16:38:04,484:INFO:create_model() successfully completed......................................
2023-12-16 16:38:04,539:INFO:SubProcess create_model() end ==================================
2023-12-16 16:38:04,539:INFO:Creating metrics dataframe
2023-12-16 16:38:04,543:INFO:Initializing SVM - Linear Kernel
2023-12-16 16:38:04,543:INFO:Total runtime is 0.04641533692677816 minutes
2023-12-16 16:38:04,544:INFO:SubProcess create_model() called ==================================
2023-12-16 16:38:04,544:INFO:Initializing create_model()
2023-12-16 16:38:04,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x285da8190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-16 16:38:04,544:INFO:Checking exceptions
2023-12-16 16:38:04,544:INFO:Importing libraries
2023-12-16 16:38:04,544:INFO:Copying training dataset
2023-12-16 16:38:04,546:INFO:Defining folds
2023-12-16 16:38:04,546:INFO:Declaring metric variables
2023-12-16 16:38:04,547:INFO:Importing untrained model
2023-12-16 16:38:04,548:INFO:SVM - Linear Kernel Imported successfully
2023-12-16 16:38:04,551:INFO:Starting cross validation
2023-12-16 16:38:04,551:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-16 16:38:04,552:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2023-12-16 16:38:04,608:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-16 16:38:04,609:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,609:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,610:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,610:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,612:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-16 16:38:04,613:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,613:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,614:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,614:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,622:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-16 16:38:04,624:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,636:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-16 16:38:04,637:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,650:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-16 16:38:04,650:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,651:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,652:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,652:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,659:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-16 16:38:04,660:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,660:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,661:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,661:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,672:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-16 16:38:04,673:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,674:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,674:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,674:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,678:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-16 16:38:04,679:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,679:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,680:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,680:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,691:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-16 16:38:04,692:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,692:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,693:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,693:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,700:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-12-16 16:38:04,701:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,701:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,702:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,702:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,712:INFO:Calculating mean and std
2023-12-16 16:38:04,713:INFO:Creating metrics dataframe
2023-12-16 16:38:04,714:INFO:Uploading results into container
2023-12-16 16:38:04,714:INFO:Uploading model into container now
2023-12-16 16:38:04,714:INFO:_master_model_container: 5
2023-12-16 16:38:04,714:INFO:_display_container: 2
2023-12-16 16:38:04,715:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7936, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-12-16 16:38:04,715:INFO:create_model() successfully completed......................................
2023-12-16 16:38:04,768:INFO:SubProcess create_model() end ==================================
2023-12-16 16:38:04,769:INFO:Creating metrics dataframe
2023-12-16 16:38:04,772:INFO:Initializing Ridge Classifier
2023-12-16 16:38:04,772:INFO:Total runtime is 0.05024120012919109 minutes
2023-12-16 16:38:04,774:INFO:SubProcess create_model() called ==================================
2023-12-16 16:38:04,774:INFO:Initializing create_model()
2023-12-16 16:38:04,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x285da8190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-16 16:38:04,774:INFO:Checking exceptions
2023-12-16 16:38:04,774:INFO:Importing libraries
2023-12-16 16:38:04,775:INFO:Copying training dataset
2023-12-16 16:38:04,776:INFO:Defining folds
2023-12-16 16:38:04,776:INFO:Declaring metric variables
2023-12-16 16:38:04,778:INFO:Importing untrained model
2023-12-16 16:38:04,779:INFO:Ridge Classifier Imported successfully
2023-12-16 16:38:04,781:INFO:Starting cross validation
2023-12-16 16:38:04,781:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-16 16:38:04,783:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2023-12-16 16:38:04,843:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-16 16:38:04,844:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,844:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,845:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,845:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,848:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-16 16:38:04,848:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,849:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,850:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,850:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,855:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-16 16:38:04,857:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,861:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-16 16:38:04,862:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,898:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-16 16:38:04,899:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,900:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,900:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,901:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,908:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-16 16:38:04,909:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,909:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,910:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,910:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,920:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-16 16:38:04,921:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,921:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,922:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,922:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,923:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-16 16:38:04,923:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,924:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,924:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,924:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,934:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-16 16:38:04,935:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,935:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,936:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,936:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,948:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-12-16 16:38:04,948:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,949:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:04,949:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:04,950:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:04,955:INFO:Calculating mean and std
2023-12-16 16:38:04,956:INFO:Creating metrics dataframe
2023-12-16 16:38:04,957:INFO:Uploading results into container
2023-12-16 16:38:04,957:INFO:Uploading model into container now
2023-12-16 16:38:04,957:INFO:_master_model_container: 6
2023-12-16 16:38:04,957:INFO:_display_container: 2
2023-12-16 16:38:04,957:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7936, solver='auto',
                tol=0.0001)
2023-12-16 16:38:04,957:INFO:create_model() successfully completed......................................
2023-12-16 16:38:05,011:INFO:SubProcess create_model() end ==================================
2023-12-16 16:38:05,011:INFO:Creating metrics dataframe
2023-12-16 16:38:05,015:INFO:Initializing Random Forest Classifier
2023-12-16 16:38:05,015:INFO:Total runtime is 0.05429383516311646 minutes
2023-12-16 16:38:05,017:INFO:SubProcess create_model() called ==================================
2023-12-16 16:38:05,017:INFO:Initializing create_model()
2023-12-16 16:38:05,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x285da8190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-16 16:38:05,017:INFO:Checking exceptions
2023-12-16 16:38:05,017:INFO:Importing libraries
2023-12-16 16:38:05,017:INFO:Copying training dataset
2023-12-16 16:38:05,018:INFO:Defining folds
2023-12-16 16:38:05,018:INFO:Declaring metric variables
2023-12-16 16:38:05,019:INFO:Importing untrained model
2023-12-16 16:38:05,020:INFO:Random Forest Classifier Imported successfully
2023-12-16 16:38:05,022:INFO:Starting cross validation
2023-12-16 16:38:05,023:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-16 16:38:05,024:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2023-12-16 16:38:05,237:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:05,237:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:05,237:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,238:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,239:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,239:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:05,240:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:05,240:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,240:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:05,241:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:05,250:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,251:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,273:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:05,274:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,276:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,277:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:05,278:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:05,319:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:05,323:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,329:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,333:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:05,335:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:05,338:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:05,342:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,345:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,348:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:05,350:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:05,412:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:05,413:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,414:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,414:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:05,414:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:05,414:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:05,415:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:05,415:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,415:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,416:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,416:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,416:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:05,416:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:05,416:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:05,416:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:05,429:INFO:Calculating mean and std
2023-12-16 16:38:05,430:INFO:Creating metrics dataframe
2023-12-16 16:38:05,431:INFO:Uploading results into container
2023-12-16 16:38:05,431:INFO:Uploading model into container now
2023-12-16 16:38:05,431:INFO:_master_model_container: 7
2023-12-16 16:38:05,431:INFO:_display_container: 2
2023-12-16 16:38:05,431:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7936, verbose=0, warm_start=False)
2023-12-16 16:38:05,431:INFO:create_model() successfully completed......................................
2023-12-16 16:38:05,489:INFO:SubProcess create_model() end ==================================
2023-12-16 16:38:05,489:INFO:Creating metrics dataframe
2023-12-16 16:38:05,495:INFO:Initializing Quadratic Discriminant Analysis
2023-12-16 16:38:05,495:INFO:Total runtime is 0.06229238907496135 minutes
2023-12-16 16:38:05,498:INFO:SubProcess create_model() called ==================================
2023-12-16 16:38:05,498:INFO:Initializing create_model()
2023-12-16 16:38:05,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x285da8190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-16 16:38:05,498:INFO:Checking exceptions
2023-12-16 16:38:05,499:INFO:Importing libraries
2023-12-16 16:38:05,499:INFO:Copying training dataset
2023-12-16 16:38:05,502:INFO:Defining folds
2023-12-16 16:38:05,502:INFO:Declaring metric variables
2023-12-16 16:38:05,504:INFO:Importing untrained model
2023-12-16 16:38:05,507:INFO:Quadratic Discriminant Analysis Imported successfully
2023-12-16 16:38:05,514:INFO:Starting cross validation
2023-12-16 16:38:05,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-16 16:38:05,519:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2023-12-16 16:38:05,565:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,572:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,572:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,572:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,572:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,572:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,572:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,574:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-12-16 16:38:05,575:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,575:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,585:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,587:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,587:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,587:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,588:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,588:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,588:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,589:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-12-16 16:38:05,589:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,590:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,602:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,614:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,624:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,624:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,624:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,624:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,624:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,624:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,625:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,625:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,625:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,625:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-12-16 16:38:05,626:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,626:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,626:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,626:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,627:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-12-16 16:38:05,628:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,630:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,636:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,636:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,636:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,636:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,636:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,636:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,637:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-12-16 16:38:05,638:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,639:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,645:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,645:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,645:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,645:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,645:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,645:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,645:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,646:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-12-16 16:38:05,647:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,653:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,653:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,653:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,654:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,654:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,654:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,654:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-12-16 16:38:05,655:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,655:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,661:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,662:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,662:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,662:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,662:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,662:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,663:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-12-16 16:38:05,664:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,672:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py", line 917, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1, covariance is ill defined.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-12-16 16:38:05,673:INFO:Calculating mean and std
2023-12-16 16:38:05,673:INFO:Creating metrics dataframe
2023-12-16 16:38:05,674:INFO:Uploading results into container
2023-12-16 16:38:05,675:INFO:Uploading model into container now
2023-12-16 16:38:05,675:INFO:_master_model_container: 8
2023-12-16 16:38:05,675:INFO:_display_container: 2
2023-12-16 16:38:05,675:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-12-16 16:38:05,675:INFO:create_model() successfully completed......................................
2023-12-16 16:38:05,735:WARNING:create_model() for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) raised an exception or returned all 0.0, trying without fit_kwargs:
2023-12-16 16:38:05,737:WARNING:Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2023-12-16 16:38:05,738:INFO:Initializing create_model()
2023-12-16 16:38:05,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x285da8190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-16 16:38:05,738:INFO:Checking exceptions
2023-12-16 16:38:05,738:INFO:Importing libraries
2023-12-16 16:38:05,738:INFO:Copying training dataset
2023-12-16 16:38:05,739:INFO:Defining folds
2023-12-16 16:38:05,739:INFO:Declaring metric variables
2023-12-16 16:38:05,740:INFO:Importing untrained model
2023-12-16 16:38:05,741:INFO:Quadratic Discriminant Analysis Imported successfully
2023-12-16 16:38:05,743:INFO:Starting cross validation
2023-12-16 16:38:05,744:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-16 16:38:05,745:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2023-12-16 16:38:05,797:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,798:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,805:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,805:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,805:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,805:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,807:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,807:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,807:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,807:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,807:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,807:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,807:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,807:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,807:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,807:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-12-16 16:38:05,808:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-12-16 16:38:05,808:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,808:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,820:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,831:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,837:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,837:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,837:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,838:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,838:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,838:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,839:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-12-16 16:38:05,840:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,844:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,849:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,849:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,849:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,850:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,850:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,850:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,851:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-12-16 16:38:05,852:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,857:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,862:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,863:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,863:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,863:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,863:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,863:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,863:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,864:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-12-16 16:38:05,864:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,867:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,867:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,868:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,868:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,868:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,868:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,869:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-12-16 16:38:05,869:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,872:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,877:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,877:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,877:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,878:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,878:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,878:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,878:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-12-16 16:38:05,879:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,887:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-12-16 16:38:05,892:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,892:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,892:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,893:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,893:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-12-16 16:38:05,893:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-12-16 16:38:05,893:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 921, in check_array
    _assert_all_finite(
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/utils/validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-12-16 16:38:05,894:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:05,904:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py", line 917, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1, covariance is ill defined.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-12-16 16:38:05,904:INFO:Calculating mean and std
2023-12-16 16:38:05,905:INFO:Creating metrics dataframe
2023-12-16 16:38:05,906:INFO:Uploading results into container
2023-12-16 16:38:05,906:INFO:Uploading model into container now
2023-12-16 16:38:05,906:INFO:_master_model_container: 9
2023-12-16 16:38:05,906:INFO:_display_container: 2
2023-12-16 16:38:05,906:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-12-16 16:38:05,906:INFO:create_model() successfully completed......................................
2023-12-16 16:38:05,962:ERROR:create_model() for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) raised an exception or returned all 0.0:
2023-12-16 16:38:05,962:ERROR:Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2023-12-16 16:38:05,962:INFO:Initializing Ada Boost Classifier
2023-12-16 16:38:05,962:INFO:Total runtime is 0.07007545232772829 minutes
2023-12-16 16:38:05,964:INFO:SubProcess create_model() called ==================================
2023-12-16 16:38:05,964:INFO:Initializing create_model()
2023-12-16 16:38:05,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x285da8190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-16 16:38:05,964:INFO:Checking exceptions
2023-12-16 16:38:05,964:INFO:Importing libraries
2023-12-16 16:38:05,964:INFO:Copying training dataset
2023-12-16 16:38:05,965:INFO:Defining folds
2023-12-16 16:38:05,966:INFO:Declaring metric variables
2023-12-16 16:38:05,967:INFO:Importing untrained model
2023-12-16 16:38:05,968:INFO:Ada Boost Classifier Imported successfully
2023-12-16 16:38:05,970:INFO:Starting cross validation
2023-12-16 16:38:05,970:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-16 16:38:05,971:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2023-12-16 16:38:06,024:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,026:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,027:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,027:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,028:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,029:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,029:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,029:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,030:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,030:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,037:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,044:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,066:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,067:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,068:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,069:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,069:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,083:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,084:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,084:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,085:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,085:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,094:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,095:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,096:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,096:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,096:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,097:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,097:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,098:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,098:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,099:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,107:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,108:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,109:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,109:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,109:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,123:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,123:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,124:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,124:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,125:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,137:INFO:Calculating mean and std
2023-12-16 16:38:06,138:INFO:Creating metrics dataframe
2023-12-16 16:38:06,139:INFO:Uploading results into container
2023-12-16 16:38:06,140:INFO:Uploading model into container now
2023-12-16 16:38:06,140:INFO:_master_model_container: 10
2023-12-16 16:38:06,140:INFO:_display_container: 2
2023-12-16 16:38:06,140:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7936)
2023-12-16 16:38:06,140:INFO:create_model() successfully completed......................................
2023-12-16 16:38:06,195:INFO:SubProcess create_model() end ==================================
2023-12-16 16:38:06,196:INFO:Creating metrics dataframe
2023-12-16 16:38:06,200:INFO:Initializing Gradient Boosting Classifier
2023-12-16 16:38:06,200:INFO:Total runtime is 0.0740401864051819 minutes
2023-12-16 16:38:06,201:INFO:SubProcess create_model() called ==================================
2023-12-16 16:38:06,201:INFO:Initializing create_model()
2023-12-16 16:38:06,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x285da8190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-16 16:38:06,201:INFO:Checking exceptions
2023-12-16 16:38:06,201:INFO:Importing libraries
2023-12-16 16:38:06,202:INFO:Copying training dataset
2023-12-16 16:38:06,203:INFO:Defining folds
2023-12-16 16:38:06,203:INFO:Declaring metric variables
2023-12-16 16:38:06,204:INFO:Importing untrained model
2023-12-16 16:38:06,205:INFO:Gradient Boosting Classifier Imported successfully
2023-12-16 16:38:06,207:INFO:Starting cross validation
2023-12-16 16:38:06,208:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-16 16:38:06,209:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2023-12-16 16:38:06,294:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,295:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,296:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,296:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,297:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,302:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,303:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,303:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,304:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,304:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,305:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,313:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,320:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,321:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,321:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,322:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,322:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,330:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,330:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,331:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,331:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,332:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,343:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,344:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,344:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,345:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,345:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,363:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,364:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,364:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,365:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,365:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,376:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,376:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,377:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,377:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,378:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,386:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,387:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,387:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,388:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,388:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,401:INFO:Calculating mean and std
2023-12-16 16:38:06,402:INFO:Creating metrics dataframe
2023-12-16 16:38:06,403:INFO:Uploading results into container
2023-12-16 16:38:06,403:INFO:Uploading model into container now
2023-12-16 16:38:06,403:INFO:_master_model_container: 11
2023-12-16 16:38:06,403:INFO:_display_container: 2
2023-12-16 16:38:06,403:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7936, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-12-16 16:38:06,403:INFO:create_model() successfully completed......................................
2023-12-16 16:38:06,461:INFO:SubProcess create_model() end ==================================
2023-12-16 16:38:06,461:INFO:Creating metrics dataframe
2023-12-16 16:38:06,466:INFO:Initializing Linear Discriminant Analysis
2023-12-16 16:38:06,466:INFO:Total runtime is 0.07847268184026084 minutes
2023-12-16 16:38:06,467:INFO:SubProcess create_model() called ==================================
2023-12-16 16:38:06,467:INFO:Initializing create_model()
2023-12-16 16:38:06,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x285da8190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-16 16:38:06,467:INFO:Checking exceptions
2023-12-16 16:38:06,467:INFO:Importing libraries
2023-12-16 16:38:06,467:INFO:Copying training dataset
2023-12-16 16:38:06,469:INFO:Defining folds
2023-12-16 16:38:06,469:INFO:Declaring metric variables
2023-12-16 16:38:06,470:INFO:Importing untrained model
2023-12-16 16:38:06,471:INFO:Linear Discriminant Analysis Imported successfully
2023-12-16 16:38:06,473:INFO:Starting cross validation
2023-12-16 16:38:06,474:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-16 16:38:06,475:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2023-12-16 16:38:06,533:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,535:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,536:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,537:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,537:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,542:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,543:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,543:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,544:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,544:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,562:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,562:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,575:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,575:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,576:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,576:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,577:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,588:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,588:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,589:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,589:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,590:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,601:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,602:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,603:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,603:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,603:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,614:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,615:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,615:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,616:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,616:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,622:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,623:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,623:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,624:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,624:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,631:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,631:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,632:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,632:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,633:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,642:INFO:Calculating mean and std
2023-12-16 16:38:06,642:INFO:Creating metrics dataframe
2023-12-16 16:38:06,643:INFO:Uploading results into container
2023-12-16 16:38:06,644:INFO:Uploading model into container now
2023-12-16 16:38:06,644:INFO:_master_model_container: 12
2023-12-16 16:38:06,644:INFO:_display_container: 2
2023-12-16 16:38:06,644:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-12-16 16:38:06,644:INFO:create_model() successfully completed......................................
2023-12-16 16:38:06,700:INFO:SubProcess create_model() end ==================================
2023-12-16 16:38:06,700:INFO:Creating metrics dataframe
2023-12-16 16:38:06,704:INFO:Initializing Extra Trees Classifier
2023-12-16 16:38:06,704:INFO:Total runtime is 0.08243933518727621 minutes
2023-12-16 16:38:06,706:INFO:SubProcess create_model() called ==================================
2023-12-16 16:38:06,706:INFO:Initializing create_model()
2023-12-16 16:38:06,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x285da8190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-16 16:38:06,706:INFO:Checking exceptions
2023-12-16 16:38:06,706:INFO:Importing libraries
2023-12-16 16:38:06,706:INFO:Copying training dataset
2023-12-16 16:38:06,708:INFO:Defining folds
2023-12-16 16:38:06,708:INFO:Declaring metric variables
2023-12-16 16:38:06,709:INFO:Importing untrained model
2023-12-16 16:38:06,710:INFO:Extra Trees Classifier Imported successfully
2023-12-16 16:38:06,713:INFO:Starting cross validation
2023-12-16 16:38:06,714:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-16 16:38:06,715:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2023-12-16 16:38:06,905:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,908:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,911:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,913:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,914:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,915:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,917:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,921:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,923:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,924:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,924:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,930:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,967:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,968:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,969:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,970:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,970:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,978:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,979:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,980:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,981:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,982:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:06,988:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:06,989:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,989:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:06,990:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:06,990:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,032:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,033:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,034:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,036:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,036:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,086:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,086:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,086:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,086:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,087:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,087:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,087:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,088:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,088:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,088:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,101:INFO:Calculating mean and std
2023-12-16 16:38:07,102:INFO:Creating metrics dataframe
2023-12-16 16:38:07,103:INFO:Uploading results into container
2023-12-16 16:38:07,103:INFO:Uploading model into container now
2023-12-16 16:38:07,103:INFO:_master_model_container: 13
2023-12-16 16:38:07,103:INFO:_display_container: 2
2023-12-16 16:38:07,104:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7936, verbose=0, warm_start=False)
2023-12-16 16:38:07,104:INFO:create_model() successfully completed......................................
2023-12-16 16:38:07,161:INFO:SubProcess create_model() end ==================================
2023-12-16 16:38:07,161:INFO:Creating metrics dataframe
2023-12-16 16:38:07,166:INFO:Initializing Light Gradient Boosting Machine
2023-12-16 16:38:07,166:INFO:Total runtime is 0.09014421701431274 minutes
2023-12-16 16:38:07,168:INFO:SubProcess create_model() called ==================================
2023-12-16 16:38:07,169:INFO:Initializing create_model()
2023-12-16 16:38:07,169:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x285da8190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-16 16:38:07,169:INFO:Checking exceptions
2023-12-16 16:38:07,169:INFO:Importing libraries
2023-12-16 16:38:07,169:INFO:Copying training dataset
2023-12-16 16:38:07,170:INFO:Defining folds
2023-12-16 16:38:07,170:INFO:Declaring metric variables
2023-12-16 16:38:07,171:INFO:Importing untrained model
2023-12-16 16:38:07,172:INFO:Light Gradient Boosting Machine Imported successfully
2023-12-16 16:38:07,174:INFO:Starting cross validation
2023-12-16 16:38:07,175:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-16 16:38:07,176:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2023-12-16 16:38:07,360:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,361:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,362:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,362:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,363:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,363:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,364:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,364:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,365:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,365:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,383:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,475:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,476:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,477:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,478:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,479:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,480:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,482:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,483:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,483:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,485:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,485:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,486:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,487:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,488:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,488:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,489:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,518:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,519:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,520:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,522:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,522:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,540:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,540:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,541:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,541:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,541:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,542:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,542:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,543:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,543:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,543:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,555:INFO:Calculating mean and std
2023-12-16 16:38:07,556:INFO:Creating metrics dataframe
2023-12-16 16:38:07,557:INFO:Uploading results into container
2023-12-16 16:38:07,557:INFO:Uploading model into container now
2023-12-16 16:38:07,557:INFO:_master_model_container: 14
2023-12-16 16:38:07,557:INFO:_display_container: 2
2023-12-16 16:38:07,558:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7936, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-12-16 16:38:07,558:INFO:create_model() successfully completed......................................
2023-12-16 16:38:07,612:INFO:SubProcess create_model() end ==================================
2023-12-16 16:38:07,612:INFO:Creating metrics dataframe
2023-12-16 16:38:07,616:INFO:Initializing Dummy Classifier
2023-12-16 16:38:07,617:INFO:Total runtime is 0.09764891862869263 minutes
2023-12-16 16:38:07,618:INFO:SubProcess create_model() called ==================================
2023-12-16 16:38:07,618:INFO:Initializing create_model()
2023-12-16 16:38:07,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x285da8190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-16 16:38:07,618:INFO:Checking exceptions
2023-12-16 16:38:07,618:INFO:Importing libraries
2023-12-16 16:38:07,618:INFO:Copying training dataset
2023-12-16 16:38:07,620:INFO:Defining folds
2023-12-16 16:38:07,620:INFO:Declaring metric variables
2023-12-16 16:38:07,620:INFO:Importing untrained model
2023-12-16 16:38:07,622:INFO:Dummy Classifier Imported successfully
2023-12-16 16:38:07,624:INFO:Starting cross validation
2023-12-16 16:38:07,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-12-16 16:38:07,625:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2023-12-16 16:38:07,677:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,678:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,679:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,679:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,679:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,689:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,693:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,694:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,694:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,695:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,695:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,705:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,710:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,711:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,711:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,712:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,713:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,725:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,725:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,726:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,726:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,727:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,737:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,738:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,739:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,739:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,739:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,751:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,751:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,752:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,752:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,752:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,758:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,759:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,759:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,760:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,760:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,766:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2023-12-16 16:38:07,766:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,767:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-12-16 16:38:07,767:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-12-16 16:38:07,768:WARNING:/Users/heeseung/miniconda3/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-12-16 16:38:07,770:INFO:Calculating mean and std
2023-12-16 16:38:07,771:INFO:Creating metrics dataframe
2023-12-16 16:38:07,773:INFO:Uploading results into container
2023-12-16 16:38:07,773:INFO:Uploading model into container now
2023-12-16 16:38:07,774:INFO:_master_model_container: 15
2023-12-16 16:38:07,774:INFO:_display_container: 2
2023-12-16 16:38:07,774:INFO:DummyClassifier(constant=None, random_state=7936, strategy='prior')
2023-12-16 16:38:07,774:INFO:create_model() successfully completed......................................
2023-12-16 16:38:07,831:INFO:SubProcess create_model() end ==================================
2023-12-16 16:38:07,831:INFO:Creating metrics dataframe
2023-12-16 16:38:07,838:INFO:Initializing create_model()
2023-12-16 16:38:07,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x282935c90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7936, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-12-16 16:38:07,838:INFO:Checking exceptions
2023-12-16 16:38:07,839:INFO:Importing libraries
2023-12-16 16:38:07,839:INFO:Copying training dataset
2023-12-16 16:38:07,840:INFO:Defining folds
2023-12-16 16:38:07,840:INFO:Declaring metric variables
2023-12-16 16:38:07,840:INFO:Importing untrained model
2023-12-16 16:38:07,840:INFO:Declaring custom model
2023-12-16 16:38:07,840:INFO:Logistic Regression Imported successfully
2023-12-16 16:38:07,841:INFO:Cross validation set to False
2023-12-16 16:38:07,841:INFO:Fitting Model
2023-12-16 16:38:07,874:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7936, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-12-16 16:38:07,874:INFO:create_model() successfully completed......................................
2023-12-16 16:38:07,937:INFO:_master_model_container: 15
2023-12-16 16:38:07,937:INFO:_display_container: 2
2023-12-16 16:38:07,937:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7936, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-12-16 16:38:07,937:INFO:compare_models() successfully completed......................................
